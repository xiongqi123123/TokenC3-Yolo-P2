"""
TokenC3-LSNetçº¯æƒé‡ç¨€ç–åŒ–ç³»ç»Ÿ
åªè¿›è¡Œæƒé‡ç¨€ç–åŒ–ï¼Œä¿æŒæ¨¡å‹ç»“æ„å®Œæ•´æ€§ï¼Œå®ç°10%å‚æ•°å‡å°‘
"""

import torch
import torch.nn as nn
import numpy as np
import copy
from ultralytics import YOLO
import os
from pathlib import Path


class PureSparsityPruner:
    """TokenC3-LSNetæ™ºèƒ½å‰ªæå™¨ï¼ˆç»“åˆæƒé‡ç¨€ç–åŒ–å’Œæ¨¡å—æ„ŸçŸ¥ç­–ç•¥ï¼‰"""
    
    def __init__(self, model_path: str, target_sparsity: float = 0.1, device: str = 'cuda:4'):
        self.model_path = model_path
        self.target_sparsity = target_sparsity
        self.device = device
        
        print(f"ğŸ§  åˆå§‹åŒ–TokenC3çº¯æƒé‡ç¨€ç–åŒ–å™¨")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"ğŸ¯ ç›®æ ‡ç¨€ç–åº¦: {target_sparsity*100:.1f}%")
        print(f"ğŸ’» è®¾å¤‡: {self.device}")
        print(f"ğŸ”§ ç­–ç•¥: çº¯æƒé‡ç¨€ç–åŒ–ï¼ˆä¿æŒç»“æ„å®Œæ•´ï¼‰")
        
        # åŠ è½½æ¨¡å‹
        self.model = self._load_model()
        self.original_params = self._count_parameters()
        self.original_nonzero = self._count_nonzero_parameters()
        
        # åˆ†ææ¨¡å‹ç»“æ„
        self._analyze_model_structure()
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"ğŸ“Š åŸå§‹å‚æ•°é‡: {self.original_params:,}")
        print(f"ğŸ“Š åŸå§‹éé›¶å‚æ•°: {self.original_nonzero:,}")
        
    def _load_model(self):
        """åŠ è½½æ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡"""
        try:
            # å‚è€ƒåŸç‰ˆyolov13çš„æˆåŠŸåšæ³•
            yolo_wrapper = YOLO(self.model_path)
            yolo_wrapper.to(self.device)
            model = yolo_wrapper.model
            model.eval()
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½æˆåŠŸ
            if model is None:
                raise RuntimeError("æ¨¡å‹åŠ è½½å¤±è´¥ï¼šmodelä¸ºNone")
            
            print(f"âœ… æ¨¡å‹æˆåŠŸåŠ è½½åˆ°è®¾å¤‡: {self.device}")
            return model
        except Exception as e:
            raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def _count_parameters(self):
        """ç»Ÿè®¡æ¨¡å‹å‚æ•°æ•°é‡"""
        return sum(p.numel() for p in self.model.parameters())
    
    def _count_nonzero_parameters(self):
        """ç»Ÿè®¡éé›¶å‚æ•°æ•°é‡"""
        return sum((p != 0).sum().item() for p in self.model.parameters())
    
    def _analyze_model_structure(self):
        """åˆ†ææ¨¡å‹ç»“æ„"""
        self.sparsity_layers = []
        
        print(f"\nğŸ” åˆ†ææ¨¡å‹ç»“æ„...")
        
        for name, module in self.model.named_modules():
            if isinstance(module, (nn.Conv2d, nn.Linear)):
                # æ’é™¤æ£€æµ‹å¤´ï¼ˆä¿æŒæ£€æµ‹ç²¾åº¦ï¼‰
                if not self._is_detection_head(name):
                    self.sparsity_layers.append((name, module))
        
        print(f"ğŸ“Š å¯ç¨€ç–åŒ–å±‚æ•°: {len(self.sparsity_layers)}")
        
        # æŒ‰æ¨¡å—ç±»å‹ç»Ÿè®¡
        self._categorize_layers()
        
    def _categorize_layers(self):
        """æŒ‰æ¨¡å—ç±»å‹åˆ†ç±»å±‚"""
        self.layer_categories = {
            'tokenc3': [],
            'hyperace': [],
            'fullpad': [],
            'dllm': [],
            'dsc3': [],
            'a2c2f': [],
            'backbone': [],
            'neck': [],
            'other': []
        }
        
        for name, module in self.sparsity_layers:
            name_lower = name.lower()
            
            if any(pattern in name_lower for pattern in ['tokenc3', 'lsconv', 'lsghost']):
                self.layer_categories['tokenc3'].append((name, module))
            elif 'hyperace' in name_lower:
                self.layer_categories['hyperace'].append((name, module))
            elif any(pattern in name_lower for pattern in ['fullpad', 'tunnel']):
                self.layer_categories['fullpad'].append((name, module))
            elif 'dllm' in name_lower:
                self.layer_categories['dllm'].append((name, module))
            elif any(pattern in name_lower for pattern in ['dsc3']):
                self.layer_categories['dsc3'].append((name, module))
            elif 'a2c2f' in name_lower:
                self.layer_categories['a2c2f'].append((name, module))
            elif any(pattern in name_lower for pattern in ['model.0', 'model.1', 'model.2', 'model.3', 'model.4', 'model.5', 'model.6', 'model.7', 'model.8']):
                self.layer_categories['backbone'].append((name, module))
            elif any(pattern in name_lower for pattern in ['model.1', 'model.2', 'model.3']):
                self.layer_categories['neck'].append((name, module))
            else:
                self.layer_categories['other'].append((name, module))
        
        # æ‰“å°åˆ†ç±»ç»Ÿè®¡
        for category, layers in self.layer_categories.items():
            if len(layers) > 0:
                print(f"ğŸ“Š {category.upper()}æ¨¡å—: {len(layers)} å±‚")
    
    def _is_detection_head(self, layer_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ£€æµ‹å¤´"""
        return 'model.31' in layer_name
    
    def _get_sparsity_ratio(self, layer_name: str) -> float:
        """
        è·å–å±‚çš„ç¨€ç–åŒ–æ¯”ä¾‹
        å‚è€ƒåŸç‰ˆYOLOv13å‰ªæçš„æˆåŠŸç­–ç•¥ï¼Œé’ˆå¯¹TokenC3-LSNetç‰¹æ®Šæ¨¡å—ä¼˜åŒ–
        """
        name_lower = layer_name.lower()
        
        # ğŸ›¡ï¸ è¶…é‡è¦æ¨¡å— - æä¿å®ˆå‰ªæ
        if any(pattern in name_lower for pattern in ['tokenc3', 'lsconv', 'lsghost']):
            return 0.06  # TokenC3åˆ›æ–°æ¨¡å—ï¼š6%ç¨€ç–åŒ–ï¼ˆç¨å¾®æé«˜ï¼‰
        elif 'hyperace' in name_lower:
            return 0.04  # HyperACEï¼š4%ç¨€ç–åŒ–ï¼ˆæœ€é‡è¦ï¼‰
        elif any(pattern in name_lower for pattern in ['lsnet', 'ls_']):
            return 0.08  # LSNetåˆ›æ–°éƒ¨åˆ†ï¼š8%ç¨€ç–åŒ–
        
        # ğŸ”§ é‡è¦æ¨¡å— - ä¿å®ˆå‰ªæ  
        elif any(pattern in name_lower for pattern in ['fullpad', 'tunnel']):
            return 0.10  # FullPADï¼š10%ç¨€ç–åŒ–
        elif any(pattern in name_lower for pattern in ['a2c2f', 'attn']):
            return 0.12  # æ³¨æ„åŠ›æ¨¡å—ï¼š12%ç¨€ç–åŒ–
        elif 'dllm' in name_lower:
            return 0.12  # DLLMï¼š12%ç¨€ç–åŒ–ï¼ˆæé«˜ä¸€äº›ï¼‰
        
        # ğŸ“Š æ ‡å‡†æ¨¡å— - é€‚åº¦å‰ªæ
        elif any(pattern in name_lower for pattern in ['dsc3', 'dsc2']):
            return 0.15  # DSCæ¨¡å—ï¼š15%ç¨€ç–åŒ–
        elif any(pattern in name_lower for pattern in ['model.0', 'model.1', 'model.2']):
            return 0.06  # éª¨å¹²æ—©æœŸå±‚ï¼š6%ç¨€ç–åŒ–ï¼ˆé‡è¦ï¼‰
        elif any(pattern in name_lower for pattern in ['model.22', 'model.24']):
            return 0.18  # ä¸Šé‡‡æ ·å±‚ï¼š18%ç¨€ç–åŒ–
        
        # âš¡ å¯ä»¥å¤§èƒ†å‰ªæçš„å±‚
        elif 'conv' in name_lower and not any(x in name_lower for x in ['tokenc3', 'lsconv']):
            return 0.22  # æ™®é€šå·ç§¯ï¼š22%ç¨€ç–åŒ–ï¼ˆæ›´ç§¯æï¼‰
        else:
            return 0.12  # å…¶ä»–å±‚ï¼š12%ç¨€ç–åŒ–
    
    def pure_sparsity_prune(self):
        """æ‰§è¡Œçº¯æƒé‡ç¨€ç–åŒ–"""
        print(f"\nğŸ”¬ å¼€å§‹çº¯æƒé‡ç¨€ç–åŒ–...")
        
        nonzero_before = self._count_nonzero_parameters()
        success_count = 0
        total_weights_processed = 0
        total_weights_sparsified = 0
        
        # æŒ‰ç±»åˆ«å¤„ç†å±‚
        for category, layers in self.layer_categories.items():
            if len(layers) == 0:
                continue
                
            print(f"\nğŸ”§ å¤„ç†{category.upper()}æ¨¡å— ({len(layers)}å±‚)...")
            category_success = 0
            
            for name, module in layers:
                try:
                    if hasattr(module, 'weight') and module.weight is not None:
                        weight = module.weight.data
                        layer_sparsity = self._get_sparsity_ratio(name)
                        
                        num_weights = weight.numel()
                        num_to_sparse = int(num_weights * layer_sparsity)
                        
                        if num_to_sparse > 0:
                            # è®¡ç®—æƒé‡é‡è¦æ€§ï¼ˆä½¿ç”¨L1 normï¼‰
                            importance = torch.abs(weight)
                            flat_importance = importance.view(-1)
                            _, indices_to_sparse = torch.topk(flat_importance, num_to_sparse, largest=False)
                            
                            # ç¨€ç–åŒ–æƒé‡
                            flat_weight = weight.view(-1)
                            flat_weight[indices_to_sparse] = 0.0
                            module.weight.data = flat_weight.view(weight.shape)
                            
                            total_weights_processed += num_weights
                            total_weights_sparsified += num_to_sparse
                            category_success += 1
                            success_count += 1
                    
                except Exception as e:
                    print(f"    âŒ {name}: ç¨€ç–åŒ–å¤±è´¥ - {e}")
            
            if category_success > 0:
                category_sparsity = total_weights_sparsified / total_weights_processed if total_weights_processed > 0 else 0
                print(f"    âœ… {category.upper()}: {category_success}/{len(layers)} å±‚æˆåŠŸ")
        
        nonzero_after = self._count_nonzero_parameters()
        effective_reduction = (nonzero_before - nonzero_after) / self.original_nonzero
        actual_sparsity = total_weights_sparsified / total_weights_processed if total_weights_processed > 0 else 0
        
        results = {
            'original_params': self.original_params,
            'final_params': self._count_parameters(),
            'original_nonzero': self.original_nonzero,
            'final_nonzero': nonzero_after,
            'weights_sparsified': total_weights_sparsified,
            'total_weights': total_weights_processed,
            'actual_sparsity': actual_sparsity,
            'effective_reduction': effective_reduction,
            'target_sparsity': self.target_sparsity,
            'layers_processed': success_count,
            'total_layers': len(self.sparsity_layers)
        }
        
        self._print_results(results)
        return results
    
    def _print_results(self, results):
        """æ‰“å°ç»“æœç»Ÿè®¡"""
        print(f"\nğŸ¯ çº¯æƒé‡ç¨€ç–åŒ–å®Œæˆ!")
        print(f"ğŸ“Š ç»“æœç»Ÿè®¡:")
        print(f"  ğŸ”µ åŸå§‹å‚æ•°: {results['original_params']:,}")
        print(f"  ğŸŸ¢ æœ€ç»ˆå‚æ•°: {results['final_params']:,}")
        print(f"  ğŸ“Š åŸå§‹éé›¶å‚æ•°: {results['original_nonzero']:,}")
        print(f"  ğŸ“Š æœ€ç»ˆéé›¶å‚æ•°: {results['final_nonzero']:,}")
        print(f"  ğŸ•¸ï¸ ç¨€ç–åŒ–æƒé‡æ•°: {results['weights_sparsified']:,}")
        print(f"  ğŸ“‰ å®é™…ç¨€ç–åº¦: {results['actual_sparsity']*100:.2f}%")
        print(f"  ğŸ“‰ æœ‰æ•ˆå‚æ•°å‡å°‘: {results['effective_reduction']*100:.2f}% (ç›®æ ‡: {results['target_sparsity']*100:.1f}%)")
        print(f"  âœ… æˆåŠŸå¤„ç†å±‚æ•°: {results['layers_processed']}/{results['total_layers']}")
        
        # é¢å¤–ç»Ÿè®¡ä¿¡æ¯
        params_reduced = results['original_params'] - results['final_params']
        model_size_reduction = params_reduced / results['original_params']
        print(f"  ğŸ“¦ æ¨¡å‹å¤§å°å‡å°‘: {model_size_reduction*100:.2f}%")
    
    def validate_structure(self):
        """éªŒè¯ç¨€ç–åŒ–åæ¨¡å‹ç»“æ„"""
        try:
            test_input = torch.randn(1, 3, 640, 640).to(self.device)
            
            print(f"ğŸ” æ¨¡å‹ç»“æ„éªŒè¯...")
            
            with torch.no_grad():
                output = self.model(test_input)
            
            print(f"âœ… æ¨¡å‹ç»“æ„éªŒè¯é€šè¿‡")
            print(f"ğŸ“Š è¾“å…¥å½¢çŠ¶: {test_input.shape}")
            if isinstance(output, (list, tuple)):
                print(f"ğŸ“Š è¾“å‡ºæ•°é‡: {len(output)}")
                for i, o in enumerate(output):
                    if hasattr(o, 'shape'):
                        print(f"ğŸ“Š è¾“å‡º{i}å½¢çŠ¶: {o.shape}")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹ç»“æ„éªŒè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def analyze_sparsity_distribution(self):
        """åˆ†æç¨€ç–åŒ–åˆ†å¸ƒ"""
        print(f"\nğŸ“Š ç¨€ç–åŒ–åˆ†å¸ƒåˆ†æ:")
        
        total_params = 0
        total_zeros = 0
        
        for category, layers in self.layer_categories.items():
            if len(layers) == 0:
                continue
                
            category_params = 0
            category_zeros = 0
            
            for name, module in layers:
                if hasattr(module, 'weight') and module.weight is not None:
                    weight = module.weight.data
                    params = weight.numel()
                    zeros = (weight == 0).sum().item()
                    
                    category_params += params
                    category_zeros += zeros
            
            if category_params > 0:
                category_sparsity = category_zeros / category_params
                print(f"  {category.upper()}: {category_sparsity*100:.2f}% ç¨€ç–åº¦ ({category_zeros:,}/{category_params:,})")
                
                total_params += category_params
                total_zeros += category_zeros
        
        if total_params > 0:
            overall_sparsity = total_zeros / total_params
            print(f"  æ•´ä½“ç¨€ç–åº¦: {overall_sparsity*100:.2f}%")
    
    def save_pruned_model(self, save_path: str):
        """ä¿å­˜ç¨€ç–åŒ–åçš„æ¨¡å‹"""
        try:
            Path(save_path).parent.mkdir(parents=True, exist_ok=True)
            
            torch.save(self.model.state_dict(), save_path)
            
            file_size_mb = os.path.getsize(save_path) / 1024 / 1024
            
            print(f"ğŸ’¾ ç¨€ç–åŒ–æ¨¡å‹å·²ä¿å­˜")
            print(f"ğŸ“ è·¯å¾„: {save_path}")
            print(f"ğŸ“¦ å¤§å°: {file_size_mb:.1f} MB")
            
            return save_path
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            return None


def main():
    """TokenC3-LSNetæ™ºèƒ½å‰ªæä¸»å‡½æ•°"""
    model_path = "/home/qi.xiong/Test/yolov13_tokenc3_lsnet_p2/yolov13_UAV_Sheep/tokenc3_lsnet_p2/weights/best.pt"
    save_path = "tokenc3_lsnet_pruned_10p.pth"  # æ›´ç›´è§‚çš„å‘½å
    device = "cuda:4"
    
    # éªŒè¯æ–‡ä»¶è·¯å¾„
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print(f"è¯·ç¡®è®¤æ¨¡å‹æ–‡ä»¶è·¯å¾„æ­£ç¡®")
        return False
    
    print(f"ğŸ“„ æ¨¡å‹è·¯å¾„éªŒè¯é€šè¿‡: {model_path}")
    
    try:
        # åˆå§‹åŒ–çº¯æƒé‡ç¨€ç–åŒ–å™¨
        pruner = PureSparsityPruner(model_path, target_sparsity=0.1, device=device)
        
        # æ‰§è¡Œçº¯æƒé‡ç¨€ç–åŒ–
        results = pruner.pure_sparsity_prune()
        
        # åˆ†æç¨€ç–åŒ–åˆ†å¸ƒ
        pruner.analyze_sparsity_distribution()
        
        # éªŒè¯æ¨¡å‹ç»“æ„
        if pruner.validate_structure():
            # ä¿å­˜ç¨€ç–åŒ–æ¨¡å‹
            saved_path = pruner.save_pruned_model(save_path)
            
            if saved_path and results['effective_reduction'] > 0.08:  # è‡³å°‘å‡å°‘8%æœ‰æ•ˆå‚æ•°
                print(f"\nğŸ‰ TokenC3-LSNetæ™ºèƒ½å‰ªææˆåŠŸ!")
                print(f"ğŸ“Š æœ‰æ•ˆå‚æ•°å‡å°‘: {results['effective_reduction']*100:.2f}%")
                print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜: {save_path}")
                print(f"\nğŸ“ ä¸‹ä¸€æ­¥éªŒè¯ç²¾åº¦:")
                print(f"  python correct_validation.py")
                print(f"    --model_path {save_path}")
                print(f"    --data_path /home/qi.xiong/Dataset/UAV_Sheep/yolo_dataset/dataset.yaml")
                return True
            else:
                print(f"\nâš ï¸ ç¨€ç–åŒ–æ•ˆæœä¸ç†æƒ³ï¼Œéœ€è¦è°ƒæ•´ç­–ç•¥")
        
        return False
        
    except Exception as e:
        print(f"âŒ çº¯æƒé‡ç¨€ç–åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    if success:
        print(f"\nâœ… çº¯æƒé‡ç¨€ç–åŒ–å®éªŒæˆåŠŸ!")
    else:
        print(f"\nâŒ çº¯æƒé‡ç¨€ç–åŒ–å®éªŒå¤±è´¥!") 