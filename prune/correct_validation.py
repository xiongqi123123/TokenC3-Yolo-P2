"""
æ­£ç¡®çš„TokenC3-LSNetç¨€ç–åŒ–æ¨¡å‹éªŒè¯è„šæœ¬
ç›´æ¥åŠ è½½ç¨€ç–åŒ–æ¨¡å‹ï¼Œé¿å…æƒé‡åŒ¹é…é—®é¢˜
"""

import torch
import torch.nn as nn
import time
import os
import argparse
import json
from PIL import Image
from ultralytics import YOLO
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval


def count_nonzero_parameters(model):
    """ç»Ÿè®¡éé›¶å‚æ•°æ•°é‡"""
    total_params = 0
    nonzero_params = 0
    
    for param in model.parameters():
        total_params += param.numel()
        nonzero_params += (param != 0).sum().item()
    
    return total_params, nonzero_params


def analyze_sparsity(model):
    """åˆ†ææ¨¡å‹ç¨€ç–åº¦"""
    print(f"\nğŸ“Š ç¨€ç–åº¦åˆ†æ:")
    
    total_params = 0
    total_zeros = 0
    layer_count = 0
    
    for name, param in model.named_parameters():
        if 'weight' in name:
            params = param.numel()
            zeros = (param == 0).sum().item()
            sparsity = zeros / params * 100
            
            total_params += params
            total_zeros += zeros
            layer_count += 1
            
            if sparsity > 1.0:  # åªæ˜¾ç¤ºç¨€ç–åº¦è¶…è¿‡1%çš„å±‚
                print(f"  {name}: {sparsity:.2f}% ç¨€ç–åº¦ ({zeros:,}/{params:,})")
    
    overall_sparsity = total_zeros / total_params * 100 if total_params > 0 else 0
    print(f"  æ•´ä½“ç¨€ç–åº¦: {overall_sparsity:.2f}% ({total_zeros:,}/{total_params:,})")
    print(f"  ç¨€ç–åŒ–å±‚æ•°: {layer_count}")
    
    return overall_sparsity


def load_sparse_model(model_path: str, pth_path: str, device: str = 'cuda:4'):
    """åŠ è½½ç¨€ç–åŒ–æ¨¡å‹"""
    print(f"\nğŸ”§ åŠ è½½ç¨€ç–åŒ–æ¨¡å‹...")
    print(f"ğŸ“ åŸå§‹æ¨¡å‹: {model_path}")
    print(f"ğŸ“ ç¨€ç–åŒ–æƒé‡: {pth_path}")
    
    try:
        # åŠ è½½åŸå§‹æ¨¡å‹ç»“æ„
        model = YOLO(model_path)
        model.to(device)
        model.eval()
        
        # åŠ è½½ç¨€ç–åŒ–æƒé‡
        sparse_state_dict = torch.load(pth_path, map_location=device)
        model.model.load_state_dict(sparse_state_dict, strict=True)
        
        print(f"âœ… ç¨€ç–åŒ–æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
        
    except Exception as e:
        print(f"âŒ ç¨€ç–åŒ–æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def validate_model_inference(model, device: str = 'cuda:4', num_runs: int = 100):
    """éªŒè¯æ¨¡å‹æ¨ç†æ€§èƒ½"""
    print(f"\nâš¡ æ¨ç†æ€§èƒ½æµ‹è¯•...")
    
    model.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    test_input = torch.randn(1, 3, 640, 640).to(device)
    
    # é¢„çƒ­
    print(f"ğŸ”¥ æ¨¡å‹é¢„çƒ­ (10æ¬¡)...")
    for _ in range(10):
        with torch.no_grad():
            outputs = model(test_input)
    
    # æ€§èƒ½æµ‹è¯•
    print(f"ğŸ“Š æ¨ç†é€Ÿåº¦æµ‹è¯• ({num_runs}æ¬¡)...")
    torch.cuda.synchronize() if device.startswith('cuda') else None
    start_time = time.time()
    
    for _ in range(num_runs):
        with torch.no_grad():
            outputs = model(test_input)
    
    torch.cuda.synchronize() if device.startswith('cuda') else None
    end_time = time.time()
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    total_time = end_time - start_time
    avg_time = total_time / num_runs * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    fps = 1000 / avg_time
    
    print(f"ğŸ“Š æ¨ç†æ€§èƒ½:")
    print(f"  â±ï¸ å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f} ms")
    print(f"  ğŸ¯ FPS: {fps:.1f}")
    print(f"  ğŸ“¦ è¾“å…¥å½¢çŠ¶: {test_input.shape}")
    
    # æ£€æŸ¥è¾“å‡º
    if isinstance(outputs, (list, tuple)):
        print(f"  ğŸ“Š è¾“å‡ºæ•°é‡: {len(outputs)}")
        for i, output in enumerate(outputs):
            if hasattr(output, 'shape'):
                print(f"  ğŸ“Š è¾“å‡º{i}å½¢çŠ¶: {output.shape}")
    else:
        print(f"  ğŸ“Š è¾“å‡ºå½¢çŠ¶: {outputs.shape if hasattr(outputs, 'shape') else type(outputs)}")
    
    return avg_time, fps


def yolo_to_coco(yolo_dir, img_dir, class_names, output_json):
    """YOLOæ ‡ç­¾è½¬COCOæ ¼å¼"""
    images = []
    annotations = []
    ann_id = 1
    img_id = 1
    
    for img_name in sorted(os.listdir(img_dir)):
        if not img_name.lower().endswith(('.jpg', '.png', '.jpeg')):
            continue
        img_path = os.path.join(img_dir, img_name)
        label_path = os.path.join(yolo_dir, os.path.splitext(img_name)[0] + '.txt')
        if not os.path.exists(label_path):
            continue
            
        img = Image.open(img_path)
        width, height = img.size
        images.append({
            "file_name": img_name,
            "height": height,
            "width": width,
            "id": img_id
        })
        
        with open(label_path) as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) != 5:
                    continue
                cls, x, y, w, h = map(float, parts)
                x1 = (x - w / 2) * width
                y1 = (y - h / 2) * height
                w_box = w * width
                h_box = h * height
                annotations.append({
                    "id": ann_id,
                    "image_id": img_id,
                    "category_id": int(cls) + 1,
                    "bbox": [x1, y1, w_box, h_box],
                    "area": w_box * h_box,
                    "iscrowd": 0
                })
                ann_id += 1
        img_id += 1
        
    categories = [{"id": i+1, "name": name} for i, name in enumerate(class_names)]
    coco_dict = {
        "images": images,
        "annotations": annotations,
        "categories": categories
    }
    
    with open(output_json, 'w') as f:
        json.dump(coco_dict, f, indent=4)
    
    return coco_dict


def validate_model_accuracy_with_coco(model, data_yaml: str, device: str = 'cuda:4'):
    """ä½¿ç”¨pycocotoolséªŒè¯æ¨¡å‹æ£€æµ‹ç²¾åº¦"""
    print(f"\nğŸ¯ æ£€æµ‹ç²¾åº¦éªŒè¯ (ä½¿ç”¨pycocotools)...")
    
    # è§£ædataset.yamlè·å–æµ‹è¯•é›†è·¯å¾„
    import yaml
    with open(data_yaml, 'r') as f:
        data_config = yaml.safe_load(f)
    
    dataset_root = data_config['path']
    test_images_dir = os.path.join(dataset_root, data_config['val'])  # valå®é™…æŒ‡å‘test
    test_labels_dir = test_images_dir.replace('images', 'labels')
    class_names = data_config['names']
    
    if not os.path.exists(test_images_dir):
        print(f"âŒ æµ‹è¯•é›†å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {test_images_dir}")
        return None
    
    if not os.path.exists(test_labels_dir):
        print(f"âŒ æµ‹è¯•é›†æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {test_labels_dir}")
        return None
    
    try:
        # 1. è½¬æ¢æ ‡ç­¾ä¸ºCOCOæ ¼å¼
        print(f"ğŸ“ è½¬æ¢YOLOæ ‡ç­¾ä¸ºCOCOæ ¼å¼...")
        coco_ann_path = 'temp_annotations_coco.json'
        coco_res_path = 'temp_results_coco.json'
        
        yolo_to_coco(test_labels_dir, test_images_dir, class_names, coco_ann_path)
        
        # 2. æ¨ç†å¹¶ä¿å­˜ä¸ºCOCOæ ¼å¼é¢„æµ‹
        print(f"ğŸ”® æ¨¡å‹æ¨ç†...")
        results = []
        img_id = 1
        
        for img_name in sorted(os.listdir(test_images_dir)):
            if not img_name.lower().endswith(('.jpg', '.png', '.jpeg')):
                continue
            img_path = os.path.join(test_images_dir, img_name)
            
            # ä½¿ç”¨æ¨¡å‹æ¨ç†
            pred = model(img_path)[0]
            boxes = pred.boxes.cpu().numpy()
            
            for box, score, cls in zip(boxes.xyxy, boxes.conf, boxes.cls):
                x1, y1, x2, y2 = box
                w = x2 - x1
                h = y2 - y1
                results.append({
                    "image_id": img_id,
                    "category_id": int(cls) + 1,
                    "bbox": [float(x1), float(y1), float(w), float(h)],
                    "score": float(score)
                })
            img_id += 1
        
        with open(coco_res_path, 'w') as f:
            json.dump(results, f)
        
        # 3. ç”¨pycocotoolsè¯„ä¼°
        print(f"ğŸ“Š ä½¿ç”¨pycocotoolsè¯„ä¼°...")
        cocoGt = COCO(coco_ann_path)
        cocoDt = cocoGt.loadRes(coco_res_path)
        cocoEval = COCOeval(cocoGt, cocoDt, 'bbox')
        cocoEval.evaluate()
        cocoEval.accumulate()
        cocoEval.summarize()
        
        # æå–å…³é”®æŒ‡æ ‡
        metrics = {
            'mAP50-95': float(cocoEval.stats[0]),  # AP @0.5:0.95
            'mAP50': float(cocoEval.stats[1]),     # AP @0.5
            'precision': 0.0,  # COCOè¯„ä¼°ä¸ç›´æ¥æä¾›precision
            'recall': 0.0      # COCOè¯„ä¼°ä¸ç›´æ¥æä¾›recall
        }
        
        print(f"ğŸ“Š æ£€æµ‹ç²¾åº¦ (pycocotools):")
        print(f"  ğŸ¯ mAP50-95: {metrics['mAP50-95']:.4f}")
        print(f"  ğŸ¯ mAP50: {metrics['mAP50']:.4f}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(coco_ann_path):
            os.remove(coco_ann_path)
        if os.path.exists(coco_res_path):
            os.remove(coco_res_path)
        
        return metrics
        
    except Exception as e:
        print(f"âŒ ç²¾åº¦éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def compare_with_original(original_path: str, sparse_path: str, data_path: str, device: str = 'cuda:4'):
    """ä¸åŸå§‹æ¨¡å‹å¯¹æ¯”"""
    print(f"\nğŸ“Š ä¸åŸå§‹æ¨¡å‹å¯¹æ¯”...")
    
    try:
        # åŠ è½½åŸå§‹æ¨¡å‹
        print(f"ğŸ”§ åŠ è½½åŸå§‹æ¨¡å‹...")
        original_model = YOLO(original_path)
        original_model.to(device)
        
        # ç»Ÿè®¡åŸå§‹æ¨¡å‹å‚æ•°
        orig_total, orig_nonzero = count_nonzero_parameters(original_model.model)
        
        # åŠ è½½ç¨€ç–åŒ–æ¨¡å‹
        sparse_model = load_sparse_model(original_path, sparse_path, device)
        if sparse_model is None:
            return
        
        # ç»Ÿè®¡ç¨€ç–åŒ–æ¨¡å‹å‚æ•°
        sparse_total, sparse_nonzero = count_nonzero_parameters(sparse_model.model)
        
        # è®¡ç®—å‡å°‘æ¯”ä¾‹
        param_reduction = (orig_total - sparse_total) / orig_total * 100
        effective_reduction = (orig_nonzero - sparse_nonzero) / orig_nonzero * 100
        
        print(f"ğŸ“Š å‚æ•°å¯¹æ¯”:")
        print(f"  ğŸ”µ åŸå§‹æ¨¡å‹æ€»å‚æ•°: {orig_total:,}")
        print(f"  ğŸ”µ åŸå§‹æ¨¡å‹éé›¶å‚æ•°: {orig_nonzero:,}")
        print(f"  ğŸŸ¢ ç¨€ç–åŒ–æ¨¡å‹æ€»å‚æ•°: {sparse_total:,}")
        print(f"  ğŸŸ¢ ç¨€ç–åŒ–æ¨¡å‹éé›¶å‚æ•°: {sparse_nonzero:,}")
        print(f"  ğŸ“‰ æ€»å‚æ•°å‡å°‘: {param_reduction:.2f}%")
        print(f"  ğŸ“‰ æœ‰æ•ˆå‚æ•°å‡å°‘: {effective_reduction:.2f}%")
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\nâš¡ æ¨ç†é€Ÿåº¦å¯¹æ¯”...")
        orig_time, orig_fps = validate_model_inference(original_model, device, 50)
        sparse_time, sparse_fps = validate_model_inference(sparse_model, device, 50)
        
        speed_improvement = (orig_time - sparse_time) / orig_time * 100
        fps_improvement = (sparse_fps - orig_fps) / orig_fps * 100
        
        print(f"ğŸ“Š é€Ÿåº¦å¯¹æ¯”:")
        print(f"  ğŸ”µ åŸå§‹æ¨¡å‹: {orig_time:.2f} ms, {orig_fps:.1f} FPS")
        print(f"  ğŸŸ¢ ç¨€ç–åŒ–æ¨¡å‹: {sparse_time:.2f} ms, {sparse_fps:.1f} FPS")
        print(f"  ğŸš€ é€Ÿåº¦æå‡: {speed_improvement:.2f}%, FPSæå‡: {fps_improvement:.2f}%")
        
        # ç²¾åº¦å¯¹æ¯”
        if os.path.exists(data_path):
            print(f"\nğŸ¯ æ£€æµ‹ç²¾åº¦å¯¹æ¯”...")
            orig_metrics = validate_model_accuracy_with_coco(original_model, data_path, device)
            sparse_metrics = validate_model_accuracy_with_coco(sparse_model, data_path, device)
            
            if orig_metrics and sparse_metrics:
                print(f"\nğŸ“Š ç²¾åº¦å¯¹æ¯”:")
                for metric in ['mAP50-95', 'mAP50']:
                    orig_val = orig_metrics[metric]
                    sparse_val = sparse_metrics[metric]
                    change = ((sparse_val - orig_val) / orig_val * 100) if orig_val > 0 else 0
                    status = "âœ…" if change > -2 else "âš ï¸" if change > -5 else "âŒ"
                    print(f"  {status} {metric}: {orig_val:.4f} â†’ {sparse_val:.4f} ({change:+.2f}%)")
        
        return {
            'param_reduction': param_reduction,
            'effective_reduction': effective_reduction,
            'speed_improvement': speed_improvement,
            'fps_improvement': fps_improvement
        }
        
    except Exception as e:
        print(f"âŒ å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(description='æ­£ç¡®éªŒè¯TokenC3-LSNetç¨€ç–åŒ–æ¨¡å‹')
    parser.add_argument('--sparse_model', type=str, 
                       default='tokenc3_pure_sparsity_10p.pth',
                       help='ç¨€ç–åŒ–æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--original_model', type=str,
                       default='/home/qi.xiong/Test/yolov13_tokenc3_lsnet_p2/yolov13_UAV_Sheep/tokenc3_lsnet_p2/weights/best.pt',
                       help='åŸå§‹æ¨¡å‹è·¯å¾„')
    parser.add_argument('--data', type=str,
                       default='/home/qi.xiong/Dataset/UAV_Sheep/yolo_dataset/dataset.yaml',
                       help='æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--device', type=str, default='cuda:4',
                       help='æ¨ç†è®¾å¤‡')
    parser.add_argument('--compare', action='store_true',
                       help='æ˜¯å¦ä¸åŸå§‹æ¨¡å‹å¯¹æ¯”')
    
    args = parser.parse_args()
    
    print("ğŸš€ TokenC3-LSNetç¨€ç–åŒ–æ¨¡å‹æ­£ç¡®éªŒè¯")
    print("="*60)
    
    # 1. åŠ è½½ç¨€ç–åŒ–æ¨¡å‹
    sparse_model = load_sparse_model(args.original_model, args.sparse_model, args.device)
    if sparse_model is None:
        print("âŒ ç¨€ç–åŒ–æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé€€å‡ºéªŒè¯")
        return
    
    # 2. åˆ†æç¨€ç–åº¦
    sparsity = analyze_sparsity(sparse_model.model)
    
    # 3. éªŒè¯æ¨ç†æ€§èƒ½
    avg_time, fps = validate_model_inference(sparse_model, args.device)
    
    # 4. éªŒè¯æ£€æµ‹ç²¾åº¦
    metrics = validate_model_accuracy_with_coco(sparse_model, args.data, args.device)
    
    # 5. ç»Ÿè®¡å‚æ•°ä¿¡æ¯
    total_params, nonzero_params = count_nonzero_parameters(sparse_model.model)
    effective_reduction = (1 - nonzero_params / total_params) * 100
    
    # 6. ä¸åŸå§‹æ¨¡å‹å¯¹æ¯”ï¼ˆå¯é€‰ï¼‰
    comparison_results = None
    if args.compare:
        comparison_results = compare_with_original(
            args.original_model, args.sparse_model, args.data, args.device
        )
    
    # 7. æ€»ç»“ç»“æœ
    print(f"\nğŸ‰ ç¨€ç–åŒ–æ¨¡å‹éªŒè¯å®Œæˆ!")
    print("="*60)
    print(f"ğŸ“Š æ ¸å¿ƒç»“æœ:")
    print(f"  ğŸ•¸ï¸ æ•´ä½“ç¨€ç–åº¦: {sparsity:.2f}%")
    print(f"  ğŸ“‰ æœ‰æ•ˆå‚æ•°å‡å°‘: {effective_reduction:.2f}%")
    print(f"  âš¡ æ¨ç†æ—¶é—´: {avg_time:.2f} ms")
    print(f"  ğŸ¯ FPS: {fps:.1f}")
    
    if metrics:
        print(f"  ğŸ¯ mAP50: {metrics['mAP50']:.4f}")
        print(f"  ğŸ¯ mAP50-95: {metrics['mAP50-95']:.4f}")
    
    if comparison_results:
        print(f"  ğŸ“ˆ ç›¸æ¯”åŸå§‹æ¨¡å‹:")
        print(f"    æœ‰æ•ˆå‚æ•°å‡å°‘: {comparison_results['effective_reduction']:.2f}%")
        print(f"    é€Ÿåº¦æå‡: {comparison_results['speed_improvement']:.2f}%")
    
    # è¯„ä¼°ç»“æœ
    success = True
    issues = []
    
    if sparsity < 8.0:
        issues.append("ç¨€ç–åº¦ä¸è¶³8%")
        success = False
    
    if metrics and metrics['mAP50'] < 0.8:
        issues.append("mAP50ä½äº0.8")
        success = False
    
    if avg_time > 25:
        issues.append("æ¨ç†æ—¶é—´è¶…è¿‡25ms")
        success = False
    
    if success:
        print(f"\nâœ… éªŒè¯æˆåŠŸ! ç¨€ç–åŒ–æ¨¡å‹æ»¡è¶³æ‰€æœ‰è¦æ±‚ã€‚")
    else:
        print(f"\nâš ï¸ éªŒè¯å‘ç°é—®é¢˜: {', '.join(issues)}")
        print(f"å»ºè®®è°ƒæ•´ç¨€ç–åŒ–ç­–ç•¥æˆ–å‚æ•°ã€‚")


if __name__ == "__main__":
    main() 